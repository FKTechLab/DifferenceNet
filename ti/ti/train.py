# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/03_train.ipynb (unless otherwise specified).

__all__ = ['device', 'BATCH_SIZE', 'EPOCHS', 'mode', 'run_name', 'get_data_and_model', 'get_prf', 'get_metric',
           'write_metric', 'train', 'test', 'train_DN', 'train_SN']

# Cell
import os
import sys
import argparse
import time

import numpy as np
import json
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

import torch
import torch.nn as nn
from torch.utils.data import DataLoader

from .dataloader import DatasetTraj, zero_padding, getSTW, splitData, file_dir
from .prep import Transformer
from .model import Difference, TrajectoryDN, TrajectorySN, ContrastiveLoss

# Cell
torch.cuda.is_available()
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
BATCH_SIZE = 4
EPOCHS = 1
mode = 'real'
run_name = f'run_5part_tran_normalsubtraj_Batch{BATCH_SIZE}_EPOCHS{EPOCHS}'
run_name

# Cell
def get_data_and_model(params, model='DN', mode='sim'):
    stw = getSTW(mode)
    tr_range, val_range = splitData(len(stw))
    # Partitions
    partition = {
        'train': tr_range,
        'validation': val_range
    }
    # Generators
    training_set = DatasetTraj(partition['train'], stw, mode=mode)
    train_g = DataLoader(training_set, **params)
    validation_set = DatasetTraj(partition['validation'], stw, mode=mode)
    val_g = DataLoader(validation_set, **params)
    transformer = Transformer()
    if model == 'DN':
        diff_net = Difference(mode='simple')
        net = TrajectoryDN(diff_net, n_features=(len(transformer.features_traj))*2) # 2x for org and dest
    else:
        net = TrajectorySN(n_features=len(transformer.features_traj))
    net = nn.DataParallel(net)
    net.to(device)
    return train_g, val_g, net

# Cell
def get_prf(y, y_p):
    p = round(precision_score(y, y_p, average='weighted'), 2)
    r = round(recall_score(y, y_p, average='weighted'), 2)
    f = round(f1_score(y, y_p, average='weighted'), 2)
    return p,r,f

def get_metric(metric, i, loss, acc, p, r, f, time):
    metric['iter'].append(i)
    metric['loss'].append(loss)
    metric['acc'].append(acc)
    metric['p'].append(p); metric['r'].append(r); metric['f'].append(f)
    metric['time_mins'].append(time)
    return metric

def write_metric(tm, vm, mtype, epoch, batch):
    file_tm = f'train_{mtype}_{epoch}_{batch}.json'
    runs_dir = os.path.join(file_dir, '../runs', run_name)
    if not os.path.exists(runs_dir):
        os.mkdir(runs_dir)
    with open (os.path.join(runs_dir, file_tm), 'w') as f:
        json.dump(tm, f)
    file_vm = f'val_{mtype}_{epoch}_{batch}.json'
    with open (os.path.join(runs_dir, file_vm), 'w') as f:
        json.dump(vm, f)

def train(model, train_g, val_g, optimizer, criterion, threshold, epoch, print_at, mtype='DN'):
    model.train()
    y_true = []
    y_pred = []
    epoch_running_loss = 0.0
    tic = time.time()
    iterations = 0
    train_metric = {
        'iter': [],
        'loss': [],
        'acc': [],
        'p': [],
        'r': [],
        'f': [],
        'time_mins': []
    }
    val_metric = {
        'iter': [],
        'loss': [],
        'acc': [],
        'p': [],
        'r': [],
        'f': [],
        'time_mins': []
    }
    for i in range(epoch):
        for x1, x2, y, x_seq_lens, max_seq_len in train_g:
            x1, y, x_seq_lens = torch.Tensor(x1).to(device), torch.Tensor(y).to(device), torch.Tensor(x_seq_lens).to(device)
            org = x2[0]
            dst = x2[1]
            org = torch.Tensor(org).to(device)
            dst = torch.Tensor(dst).to(device)
            x2 = [org, dst]
            # y = torch.Tensor(y)
            # Zero your gradients for every batch!
            optimizer.zero_grad()
            #FORWARD PASS
            if mtype == 'DN':
                output = model(x1, x2, x_seq_lens)
                output = torch.squeeze(output)
                if len(output.shape) == 0:
                    output = output.unsqueeze(0)
                loss = criterion(output, y)
                predicted_vals = (output > threshold)*1
            else:
                out1, out2 = model(x1, x2, x_seq_lens)
                loss = criterion(out1, out2, y)
                predicted_vals = (torch.pairwise_distance(out1, out2) > threshold)*1
            # Compute the loss and its gradients
            loss.backward()
            # Adjust learning weights
            optimizer.step()
            epoch_running_loss += loss.item()
            # Store Predictions
            y_pred.extend(predicted_vals.tolist())
            y_true.extend(y.tolist())
            iterations += 1
        MODEL_SAVE_PATH = os.path.join(file_dir, '../runs', run_name, f'Epoch{i}.pth')
        if not os.path.exists(os.path.join(file_dir, '../runs', run_name)):
            os.mkdir(os.path.join(file_dir, '../runs', run_name))
        torch.save({
            'epoch': i,
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'loss': loss,
            }, MODEL_SAVE_PATH)
        if i % print_at == print_at-1:
            train_time = round((time.time()-tic)/60.0, 2)
            print(f'Epoch Time (min): {train_time}')
            train_loss = round(epoch_running_loss / iterations, 4) # avg loss
            train_acc = round(accuracy_score(y_true, y_pred), 2)
            tp, tr, tf = get_prf(y_true, y_pred)
            train_metric = get_metric(train_metric, i+1, train_loss, train_acc, tp, tr, tf, train_time)
            tic = time.time()
            val_loss, val_acc, vp, vr, vf = test(model, val_g, criterion, threshold, mtype)
            val_time = round((time.time()-tic)/60.0, 2)
            val_metric = get_metric(val_metric, i+1, val_loss, val_acc, vp, vr, vf, val_time)
            print(f'Prediction Time (min): {val_time}')
            print(
                f'Epoch {i + 1}, Loss (Train, Val) : {train_loss}, {val_loss}, Accuracy (Train, Val): {train_acc}, {val_acc}, PRF (Val): {vp},{vr},{vf}'
            )
            print("***********************************************************")
            write_metric(train_metric, val_metric, mtype, epoch, train_g.batch_size)
            tic = time.time()
            model.train()
    return train_metric, val_metric

def test(model, test_loader, criterion, threshold, mtype='DN'):
    #model in eval mode skips Dropout etc
    model.eval()
    y_true = []
    y_pred = []
    running_loss = 0.0
    # set the requires_grad flag to false as we are in the test mode
    with torch.no_grad():
        for x1, x2, y, x_seq_lens, max_seq_len in test_loader:
            x1, y, x_seq_lens = torch.Tensor(x1).to(device), torch.Tensor(y).to(device), torch.Tensor(x_seq_lens).to(device)
            org = x2[0]
            dst = x2[1]
            org = torch.Tensor(org).to(device)
            dst = torch.Tensor(dst).to(device)
            x2 = [org, dst]
            # y = torch.Tensor(y)
            # the model on the data
            if mtype == 'DN':
                output = model(x1, x2, x_seq_lens)
                output = torch.squeeze(output)
                if len(output.shape) == 0:
                    output = output.unsqueeze(0)
                loss = criterion(output, y)
                pred = np.array((output.cpu() > threshold)*1)
            else:
                out1, out2 = model(x1, x2, x_seq_lens)
                loss = criterion(out1, out2, y)
                pred = np.array((torch.pairwise_distance(out1, out2) > threshold)*1)
            target = y.float()
            running_loss += loss.item()
            y_true.extend(target.tolist())
            y_pred.extend(pred.reshape(-1).tolist())
    avg_loss = round(running_loss / len(test_loader), 4)
    acc = round(accuracy_score(y_true, y_pred), 2)
    p,r,f = get_prf(y_true, y_pred)
    return avg_loss, acc, p,r,f


# Cell
def train_DN(train_g, val_g, net, lr, threshold, num_epochs, print_at):
    criterion = nn.BCELoss()
    optimizer = torch.optim.Adam(net.parameters(), lr=lr)
    train_metric, val_metric = train(
        net, train_g, val_g, optimizer, criterion, threshold, num_epochs, print_at, mtype='DN'
    )
    return train_metric, val_metric

# Cell
def train_SN(train_g, val_g, net, lr, threshold, num_epochs, print_at):
    criterion = ContrastiveLoss()
    optimizer = torch.optim.Adam(net.parameters(), lr=lr)
    train_metric, val_metric = train(
        net, train_g, val_g, optimizer, criterion, threshold, num_epochs, print_at, mtype='SN'
    )
    return train_metric, val_metric

# Cell
if __name__ == '__main__' and '__file__' in globals():
    args = sys.argv[1:]
    parser = argparse.ArgumentParser()
    models = ['SN', 'DN']
    parser.add_argument(
        '-m', '--model',
        help="""Choose model, SN : Siamese Net, DN : Difference Net""",
        choices=models
    )
    parser.add_argument(
        '-e', '--epoch',
        help="""Number of Epochs"""
    )
    parser.add_argument(
        '-p', '--print',
        help="""Print at every p step, p must not be greater than e"""
    )
    results = parser.parse_args(args)
    params = {
        'batch_size': 4,
        'shuffle': True,
        'collate_fn': zero_padding
    }
    lr = 1e-3
    threshold = 0.5
    num_epochs = int(results.epoch) if results.epoch else 10
    print_at = int(results.print) if results.print else 1
    if print_at > num_epochs:
        raise ValueError('p must not be greater than e')
    mtype = results.model if results.model else 'DN'
    print(f'Training starting with: model={mtype}, epoch={num_epochs}, print every={print_at}')
    train_g, val_g, net = get_data_and_model(params, mtype)
    if mtype == 'DN':
        train_DN(train_g, val_g, net, lr, threshold, num_epochs, print_at)
    else:
        train_SN(train_g, val_g, net, lr, threshold, num_epochs, print_at)