{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Dataloader\n",
    "\n",
    "> The data generator module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from nbdev.showdoc import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from random import randrange\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from ti.prep import Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "file_dir = os.path.dirname(os.path.realpath(__file__)) if '__file__' in globals() else './'\n",
    "def getSTW(mode='sim'):\n",
    "    window_file = os.path.join(file_dir, '../data/%s/'%(mode), 'space_time_windows')\n",
    "    if not os.path.exists(window_file):\n",
    "        print('Space time window doesn\\'t exist create one first!: ', window_file)\n",
    "        raise NotADirectoryError(\"Data folder not found\")\n",
    "    with open (window_file, 'rb') as fp:\n",
    "        space_time_window_list = pickle.load(fp)\n",
    "    return space_time_window_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "# slow\n",
    "# usage: getSTW\n",
    "mode = 'sim'\n",
    "stw = getSTW(mode=mode)\n",
    "print(len(stw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def splitData(size):\n",
    "    train_size = int(size*0.8) # 80%\n",
    "    val_size = int(size*0.1) # 10%\n",
    "    test_size = size - (train_size+val_size) # 10%\n",
    "    return (range(train_size), \n",
    "            range(train_size, train_size+val_size), \n",
    "            range(train_size+val_size, train_size+val_size+test_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range (train, val, test): (range(0, 9), range(9, 10), range(10, 12))\n"
     ]
    }
   ],
   "source": [
    "# slow\n",
    "# usage: splitData\n",
    "train_range, val_range, test_range = splitData(len(stw))\n",
    "print(f'Range (train, val, test): {train_range, val_range, test_range}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class DatasetTraj(Dataset):\n",
    "    '''Characterizes a dataset for PyTorch'''\n",
    "    def __init__(self, list_ids, space_time_window_list, mode='sim'):\n",
    "        self.list_ids = list_ids\n",
    "        self.mode = mode\n",
    "        self.space_time_window_list = space_time_window_list\n",
    "        self.trasformer = Transformer()\n",
    "\n",
    "    def __len__(self):\n",
    "        '''Denotes the total number of samples'''\n",
    "        return len(self.list_ids)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        '''Generates one sample of data'''\n",
    "        id = self.list_ids[index]\n",
    "        is_positive = random.getrandbits(1) # label\n",
    "        \n",
    "        # Select sample\n",
    "        if is_positive:\n",
    "            # Load data and get label\n",
    "            if self.mode == 'sim':\n",
    "                data = pd.read_csv(f'{file_dir}/../data/sim/{str(id)}.csv')\n",
    "            else:\n",
    "                window = self.space_time_window_list[id]\n",
    "                tid = random.choice(window)\n",
    "                data = pd.read_csv(f'{file_dir}/../data/real/{str(int(tid))}.csv')\n",
    "            x1, org= self.trasformer.transform(data)\n",
    "            total_steps = len(x1)\n",
    "            dst_idx = randrange(int(0.7*total_steps), total_steps - 1)\n",
    "            dst = x1[dst_idx]\n",
    "            c_range = randrange(int(.25*dst_idx), int(.9*dst_idx))#total_steps#\n",
    "            x1 = x1[:c_range]\n",
    "            org = org[:c_range]\n",
    "            dst = [dst] * len(org)\n",
    "            x2 = [org, dst]\n",
    "            y = 1\n",
    "        else:\n",
    "            # Load data and get label\n",
    "            window = self.space_time_window_list[id]\n",
    "            ids = random.sample(window, 2)\n",
    "            pid, nid = ids[0], ids[1]\n",
    "            if self.mode == 'sim':\n",
    "                pid, nid = ids[0], ids[1]\n",
    "                pos_data = pd.read_csv(f'{file_dir}/../data/sim/{str(int(pid))}.csv')\n",
    "                neg_data = pd.read_csv(f'{file_dir}/../data/sim/{str(int(nid))}.csv')\n",
    "            else:\n",
    "                pos_data = pd.read_csv(f'{file_dir}/../data/real/{str(int(pid))}.csv')\n",
    "                neg_data = pd.read_csv(f'{file_dir}/../data/real/{str(int(nid))}.csv')\n",
    "            pos_x1, pos_org = self.trasformer.transform(pos_data)\n",
    "            neg_x1, neg_org = self.trasformer.transform(neg_data)\n",
    "\n",
    "            neg_total_steps = len(neg_x1)\n",
    "            pos_total_steps = len(pos_x1)\n",
    "            dst_idx = randrange(int(0.7*pos_total_steps), pos_total_steps - 1)\n",
    "            dst = pos_x1[dst_idx]\n",
    "            c_range = randrange(int(.25*neg_total_steps), int(.9*neg_total_steps))\n",
    "            x1 = neg_x1[:c_range]\n",
    "            org = [neg_org[0]] * len(x1)\n",
    "            dst = [dst] * len(x1)\n",
    "            x2 = [org, dst]\n",
    "            y = 0\n",
    "        \n",
    "        return x1, x2, y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"DatasetTraj\" class=\"doc_header\"><code>class</code> <code>DatasetTraj</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h2>\n",
       "\n",
       "> <code>DatasetTraj</code>(**\\*`args`**, **\\*\\*`kwds`**) :: `Dataset`\n",
       "\n",
       "Characterizes a dataset for PyTorch"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(DatasetTraj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def zero_padding(batch):\n",
    "    '''Pads batch of variable length with leading zeros'''\n",
    "    x1 = [item[0] for item in batch]\n",
    "    x2_org = [item[1][0] for item in batch]\n",
    "    x2_dst = [item[1][1] for item in batch]\n",
    "    y = [item[2] for item in batch]\n",
    "    x_seq_lens = [len(item) for item in x1]\n",
    "    max_seq_len = max(x_seq_lens)\n",
    "    n_dim = len(x1[0][0])\n",
    "    x1_pad = torch.FloatTensor([\n",
    "        np.zeros((max_seq_len-len(item), n_dim)).tolist()+item\n",
    "        for item in x1\n",
    "    ])\n",
    "    x2_org_pad = torch.FloatTensor([\n",
    "        np.zeros((max_seq_len-len(item), n_dim)).tolist()+item\n",
    "        for item in x2_org\n",
    "    ])\n",
    "    x2_dst_pad = torch.FloatTensor([\n",
    "        np.zeros((max_seq_len-len(item), n_dim)).tolist()+item\n",
    "        for item in x2_dst\n",
    "    ])\n",
    "    return x1_pad, (x2_org_pad, x2_dst_pad), y, x_seq_lens, max_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"zero_padding\" class=\"doc_header\"><code>zero_padding</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>zero_padding</code>(**`batch`**)\n",
       "\n",
       "Pads batch of variable length with leading zeros"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(zero_padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slow\n",
    "# usage: DatasetTraj\n",
    "# Parameters\n",
    "params = {\n",
    "    'batch_size': 4,\n",
    "    'shuffle': True,\n",
    "    'collate_fn': zero_padding\n",
    "}\n",
    "\n",
    "# Partitions\n",
    "partition = {\n",
    "    'train': train_range,\n",
    "    'validation': val_range\n",
    "}\n",
    "\n",
    "# Generators\n",
    "training_set = DatasetTraj(partition['train'], stw, mode=mode)\n",
    "training_generator = DataLoader(training_set, **params)\n",
    "\n",
    "validation_set = DatasetTraj(partition['validation'], stw, mode=mode)\n",
    "validation_generator = DataLoader(validation_set, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch\n",
      "torch.Size([4, 11, 4])\n",
      "torch.Size([4, 11, 4]) torch.Size([4, 11, 4])\n",
      "[1, 1, 1, 1]\n",
      "[2, 10, 3, 11]\n",
      "11\n",
      "Batch\n",
      "torch.Size([4, 9, 4])\n",
      "torch.Size([4, 9, 4]) torch.Size([4, 9, 4])\n",
      "[0, 0, 0, 1]\n",
      "[4, 9, 8, 3]\n",
      "9\n",
      "Batch\n",
      "torch.Size([1, 6, 4])\n",
      "torch.Size([1, 6, 4]) torch.Size([1, 6, 4])\n",
      "[1]\n",
      "[6]\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "# slow\n",
    "# usage: Training Generator\n",
    "count = 0\n",
    "for x1, x2, y, x_seq_lens, max_seq_len in training_generator:\n",
    "    print('Batch')\n",
    "    print(x1.shape)\n",
    "    print(x2[0].shape, x2[0].shape)\n",
    "    print(y)\n",
    "    print(x_seq_lens)\n",
    "    print(max_seq_len)\n",
    "    if count >=2:\n",
    "        break\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_prep.ipynb.\n",
      "Converted 01_dataloader.ipynb.\n",
      "Converted 02_model.ipynb.\n",
      "Converted 03_train.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
