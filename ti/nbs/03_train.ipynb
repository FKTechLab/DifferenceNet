{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train\n",
    "\n",
    "> Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from nbdev.showdoc import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from ti.dataloader import DatasetTraj, zero_padding, getSTW, splitData, file_dir\n",
    "from ti.prep import Transformer\n",
    "from ti.model import Difference, TrajectoryDN, TrajectorySN, ContrastiveLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'run_5part_tran_normalsubtraj_Batch4_EPOCHS1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# export\n",
    "torch.cuda.is_available()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "BATCH_SIZE = 4\n",
    "EPOCHS = 1\n",
    "mode = 'real'\n",
    "run_name = f'run_5part_tran_normalsubtraj_Batch{BATCH_SIZE}_EPOCHS{EPOCHS}'\n",
    "run_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_data_and_model(params, model='DN', mode='sim'):\n",
    "    stw = getSTW(mode)\n",
    "    tr_range, val_range = splitData(len(stw))\n",
    "    # Partitions\n",
    "    partition = {\n",
    "        'train': tr_range,\n",
    "        'validation': val_range\n",
    "    }\n",
    "    # Generators\n",
    "    training_set = DatasetTraj(partition['train'], stw, mode=mode)\n",
    "    train_g = DataLoader(training_set, **params)\n",
    "    validation_set = DatasetTraj(partition['validation'], stw, mode=mode)\n",
    "    val_g = DataLoader(validation_set, **params)\n",
    "    transformer = Transformer()\n",
    "    if model == 'DN':\n",
    "        diff_net = Difference(mode='simple')\n",
    "        net = TrajectoryDN(diff_net, n_features=(len(transformer.features_traj))*2) # 2x for org and dest \n",
    "    else:\n",
    "        net = TrajectorySN(n_features=len(transformer.features_traj)) \n",
    "    net = nn.DataParallel(net)\n",
    "    net.to(device)\n",
    "    return train_g, val_g, net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 0\n",
      "torch.Size([16, 59, 4])\n",
      "torch.Size([16, 59, 4]) torch.Size([16, 59, 4])\n",
      "[0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1]\n",
      "[27, 49, 35, 50, 24, 14, 25, 59, 14, 32, 20, 30, 56, 31, 29, 11]\n",
      "59\n",
      "Batch: 1\n",
      "torch.Size([16, 88, 4])\n",
      "torch.Size([16, 88, 4]) torch.Size([16, 88, 4])\n",
      "[1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1]\n",
      "[37, 23, 30, 88, 16, 10, 16, 21, 26, 19, 18, 28, 43, 48, 19, 52]\n",
      "88\n",
      "Batch: 2\n",
      "torch.Size([16, 51, 4])\n",
      "torch.Size([16, 51, 4]) torch.Size([16, 51, 4])\n",
      "[1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1]\n",
      "[18, 18, 21, 31, 9, 45, 25, 22, 15, 51, 12, 22, 12, 20, 25, 11]\n",
      "51\n"
     ]
    }
   ],
   "source": [
    "# slow\n",
    "params = {\n",
    "    'batch_size': 16,\n",
    "    'shuffle': True,\n",
    "    'collate_fn': zero_padding\n",
    "}\n",
    "train_g, val_g, net = get_data_and_model(params, mode=mode)\n",
    "count = 0\n",
    "for i, (x1, x2, y, x_seq_lens, max_seq_len) in enumerate(train_g):\n",
    "    print(f'Batch: {i}')\n",
    "    print(x1.shape)\n",
    "    print(x2[0].shape, x2[0].shape)\n",
    "    print(y)\n",
    "    print(x_seq_lens)\n",
    "    print(max_seq_len)\n",
    "    if count >=2:\n",
    "        break\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_prf(y, y_p):\n",
    "    p = round(precision_score(y, y_p, average='weighted'), 2)\n",
    "    r = round(recall_score(y, y_p, average='weighted'), 2)\n",
    "    f = round(f1_score(y, y_p, average='weighted'), 2)\n",
    "    return p,r,f\n",
    "\n",
    "def get_metric(metric, i, loss, acc, p, r, f, time):\n",
    "    metric['iter'].append(i)\n",
    "    metric['loss'].append(loss)\n",
    "    metric['acc'].append(acc)\n",
    "    metric['p'].append(p); metric['r'].append(r); metric['f'].append(f)\n",
    "    metric['time_mins'].append(time)\n",
    "    return metric\n",
    "\n",
    "def write_metric(tm, vm, mtype, epoch, batch):\n",
    "    file_tm = f'train_{mtype}_{epoch}_{batch}.json'\n",
    "    runs_dir = os.path.join(file_dir, '../runs', run_name)\n",
    "    if not os.path.exists(runs_dir):\n",
    "        os.mkdir(runs_dir)\n",
    "    with open (os.path.join(runs_dir, file_tm), 'w') as f:\n",
    "        json.dump(tm, f)\n",
    "    file_vm = f'val_{mtype}_{epoch}_{batch}.json'\n",
    "    with open (os.path.join(runs_dir, file_vm), 'w') as f:\n",
    "        json.dump(vm, f)\n",
    "\n",
    "def train(model, train_g, val_g, optimizer, criterion, threshold, epoch, print_at, mtype='DN'):\n",
    "    model.train()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    epoch_running_loss = 0.0\n",
    "    tic = time.time()\n",
    "    iterations = 0\n",
    "    train_metric = {\n",
    "        'iter': [],\n",
    "        'loss': [],\n",
    "        'acc': [],\n",
    "        'p': [],\n",
    "        'r': [],\n",
    "        'f': [],\n",
    "        'time_mins': []\n",
    "    }\n",
    "    val_metric = {\n",
    "        'iter': [],\n",
    "        'loss': [],\n",
    "        'acc': [],\n",
    "        'p': [],\n",
    "        'r': [],\n",
    "        'f': [],\n",
    "        'time_mins': []\n",
    "    }\n",
    "    for i in range(epoch):\n",
    "        for x1, x2, y, x_seq_lens, max_seq_len in train_g:\n",
    "            x1, y, x_seq_lens = torch.Tensor(x1).to(device), torch.Tensor(y).to(device), torch.Tensor(x_seq_lens).to(device)\n",
    "            org = x2[0]\n",
    "            dst = x2[1]\n",
    "            org = torch.Tensor(org).to(device)\n",
    "            dst = torch.Tensor(dst).to(device)\n",
    "            x2 = [org, dst]\n",
    "            # y = torch.Tensor(y)\n",
    "            # Zero your gradients for every batch!\n",
    "            optimizer.zero_grad()\n",
    "            #FORWARD PASS\n",
    "            if mtype == 'DN':\n",
    "                output = model(x1, x2, x_seq_lens)\n",
    "                output = torch.squeeze(output)\n",
    "                if len(output.shape) == 0:\n",
    "                    output = output.unsqueeze(0)\n",
    "                loss = criterion(output, y) \n",
    "                predicted_vals = (output > threshold)*1\n",
    "            else:\n",
    "                out1, out2 = model(x1, x2, x_seq_lens)\n",
    "                loss = criterion(out1, out2, y)\n",
    "                predicted_vals = (torch.pairwise_distance(out1, out2) > threshold)*1\n",
    "            # Compute the loss and its gradients\n",
    "            loss.backward()\n",
    "            # Adjust learning weights\n",
    "            optimizer.step()\n",
    "            epoch_running_loss += loss.item()\n",
    "            # Store Predictions\n",
    "            y_pred.extend(predicted_vals.tolist())\n",
    "            y_true.extend(y.tolist())\n",
    "            iterations += 1\n",
    "        MODEL_SAVE_PATH = os.path.join(file_dir, '../runs', run_name, f'Epoch{i}.pth')\n",
    "        if not os.path.exists(os.path.join(file_dir, '../runs', run_name)):\n",
    "            os.mkdir(os.path.join(file_dir, '../runs', run_name))\n",
    "        torch.save({\n",
    "            'epoch': i,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "            }, MODEL_SAVE_PATH)\n",
    "        if i % print_at == print_at-1:\n",
    "            train_time = round((time.time()-tic)/60.0, 2)\n",
    "            print(f'Epoch Time (min): {train_time}')\n",
    "            train_loss = round(epoch_running_loss / iterations, 4) # avg loss\n",
    "            train_acc = round(accuracy_score(y_true, y_pred), 2)\n",
    "            tp, tr, tf = get_prf(y_true, y_pred)\n",
    "            train_metric = get_metric(train_metric, i+1, train_loss, train_acc, tp, tr, tf, train_time)\n",
    "            tic = time.time()\n",
    "            val_loss, val_acc, vp, vr, vf = test(model, val_g, criterion, threshold, mtype)\n",
    "            val_time = round((time.time()-tic)/60.0, 2)\n",
    "            val_metric = get_metric(val_metric, i+1, val_loss, val_acc, vp, vr, vf, val_time)\n",
    "            print(f'Prediction Time (min): {val_time}')\n",
    "            print(\n",
    "                f'Epoch {i + 1}, Loss (Train, Val) : {train_loss}, {val_loss}, Accuracy (Train, Val): {train_acc}, {val_acc}, PRF (Val): {vp},{vr},{vf}'\n",
    "            )\n",
    "            print(\"***********************************************************\")\n",
    "            write_metric(train_metric, val_metric, mtype, epoch, train_g.batch_size)\n",
    "            tic = time.time()\n",
    "            model.train()\n",
    "    return train_metric, val_metric\n",
    "                          \n",
    "def test(model, test_loader, criterion, threshold, mtype='DN'):\n",
    "    #model in eval mode skips Dropout etc\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    running_loss = 0.0\n",
    "    # set the requires_grad flag to false as we are in the test mode\n",
    "    with torch.no_grad():\n",
    "        for x1, x2, y, x_seq_lens, max_seq_len in test_loader:\n",
    "            x1, y, x_seq_lens = torch.Tensor(x1).to(device), torch.Tensor(y).to(device), torch.Tensor(x_seq_lens).to(device)\n",
    "            org = x2[0]\n",
    "            dst = x2[1]\n",
    "            org = torch.Tensor(org).to(device)\n",
    "            dst = torch.Tensor(dst).to(device)\n",
    "            x2 = [org, dst]\n",
    "            # y = torch.Tensor(y)\n",
    "            # the model on the data\n",
    "            if mtype == 'DN':\n",
    "                output = model(x1, x2, x_seq_lens)\n",
    "                output = torch.squeeze(output)\n",
    "                if len(output.shape) == 0:\n",
    "                    output = output.unsqueeze(0)\n",
    "                loss = criterion(output, y) \n",
    "                pred = np.array((output.cpu() > threshold)*1)\n",
    "            else:\n",
    "                out1, out2 = model(x1, x2, x_seq_lens)\n",
    "                loss = criterion(out1, out2, y)\n",
    "                pred = np.array((torch.pairwise_distance(out1, out2) > threshold)*1)\n",
    "            target = y.float()\n",
    "            running_loss += loss.item()\n",
    "            y_true.extend(target.tolist()) \n",
    "            y_pred.extend(pred.reshape(-1).tolist())\n",
    "    avg_loss = round(running_loss / len(test_loader), 4)\n",
    "    acc = round(accuracy_score(y_true, y_pred), 2)\n",
    "    p,r,f = get_prf(y_true, y_pred)\n",
    "    return avg_loss, acc, p,r,f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def train_DN(train_g, val_g, net, lr, threshold, num_epochs, print_at):\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    train_metric, val_metric = train(\n",
    "        net, train_g, val_g, optimizer, criterion, threshold, num_epochs, print_at, mtype='DN'\n",
    "    )\n",
    "    return train_metric, val_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def train_SN(train_g, val_g, net, lr, threshold, num_epochs, print_at):\n",
    "    criterion = ContrastiveLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    train_metric, val_metric = train(\n",
    "        net, train_g, val_g, optimizer, criterion, threshold, num_epochs, print_at, mtype='SN'\n",
    "    )\n",
    "    return train_metric, val_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-trained model and optimizer weights from  /Users/mahantesh/data/2022/DS/A3/git_workspace/DifferenceNet/ti/ti/../runs/run_tran_normalsubtraj_Batch4_EPOCHS1000/Epoch999.pth\n",
      "Epoch Time (min): 1.42\n"
     ]
    }
   ],
   "source": [
    "# slow\n",
    "# usage: train_DN\n",
    "params = {\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'shuffle': True,\n",
    "    'collate_fn': zero_padding\n",
    "}\n",
    "lr = 1e-3\n",
    "threshold = 0.5\n",
    "num_epochs = EPOCHS\n",
    "print_at = 1\n",
    "train_g, val_g, net = get_data_and_model(params, model='DN', mode=mode)\n",
    "prev_run_name = f'run_tran_normalsubtraj_Batch4_EPOCHS1000'\n",
    "MODEL_SAVE_PATH = os.path.join(file_dir, '../runs', prev_run_name, f'Epoch{999}.pth')\n",
    "if os.path.exists(MODEL_SAVE_PATH):\n",
    "    print('Loading pre-trained model and optimizer weights from ', MODEL_SAVE_PATH)\n",
    "    checkpoint = torch.load(MODEL_SAVE_PATH)\n",
    "    net.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    net.train()\n",
    "else:\n",
    "    print('Did not find pre-trained weights at %s, starting training without them'%(MODEL_SAVE_PATH))\n",
    "_, _ = train_DN(train_g, val_g, net, lr, threshold, num_epochs, print_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "if __name__ == '__main__' and '__file__' in globals():\n",
    "    args = sys.argv[1:]\n",
    "    parser = argparse.ArgumentParser()\n",
    "    models = ['SN', 'DN']\n",
    "    parser.add_argument(\n",
    "        '-m', '--model',\n",
    "        help=\"\"\"Choose model, SN : Siamese Net, DN : Difference Net\"\"\",\n",
    "        choices=models\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '-e', '--epoch',\n",
    "        help=\"\"\"Number of Epochs\"\"\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '-p', '--print',\n",
    "        help=\"\"\"Print at every p step, p must not be greater than e\"\"\"\n",
    "    )\n",
    "    results = parser.parse_args(args)\n",
    "    params = {\n",
    "        'batch_size': 4,\n",
    "        'shuffle': True,\n",
    "        'collate_fn': zero_padding\n",
    "    }\n",
    "    lr = 1e-3\n",
    "    threshold = 0.5\n",
    "    num_epochs = int(results.epoch) if results.epoch else 10\n",
    "    print_at = int(results.print) if results.print else 1\n",
    "    if print_at > num_epochs:\n",
    "        raise ValueError('p must not be greater than e')\n",
    "    mtype = results.model if results.model else 'DN'\n",
    "    print(f'Training starting with: model={mtype}, epoch={num_epochs}, print every={print_at}')\n",
    "    train_g, val_g, net = get_data_and_model(params, mtype)\n",
    "    if mtype == 'DN':\n",
    "        train_DN(train_g, val_g, net, lr, threshold, num_epochs, print_at)\n",
    "    else:\n",
    "        train_SN(train_g, val_g, net, lr, threshold, num_epochs, print_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "a3_pytorch",
   "language": "python",
   "name": "a3_pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
