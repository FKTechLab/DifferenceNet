{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train\n",
    "\n",
    "> Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from nbdev.showdoc import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from ti.dataloader import DatasetTraj, zero_padding, getSTW, splitData, file_dir\n",
    "from ti.prep import Transformer\n",
    "from ti.model import Difference, TrajectoryDN, TrajectorySN, ContrastiveLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'run_simulatedsubtraj_Batch4_EPOCHS10'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# export\n",
    "torch.cuda.is_available()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "BATCH_SIZE = 4\n",
    "EPOCHS = 10\n",
    "mode = 'sim'\n",
    "run_name = f'run_simulatedsubtraj_Batch{BATCH_SIZE}_EPOCHS{EPOCHS}'\n",
    "run_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_data_and_model(params, model='DN', mode='sim'):\n",
    "    stw = getSTW(mode)\n",
    "    tr_range, val_range, ts_range = splitData(len(stw))\n",
    "    # Partitions\n",
    "    partition = {\n",
    "        'train': tr_range,\n",
    "        'validation': val_range\n",
    "    }\n",
    "    # Generators\n",
    "    training_set = DatasetTraj(partition['train'], stw, mode=mode)\n",
    "    train_g = DataLoader(training_set, **params)\n",
    "    validation_set = DatasetTraj(partition['validation'], stw, mode=mode)\n",
    "    val_g = DataLoader(validation_set, **params)\n",
    "    transformer = Transformer()\n",
    "    if model == 'DN':\n",
    "        diff_net = Difference(mode='simple')\n",
    "        net = TrajectoryDN(diff_net, n_features=(len(transformer.features_traj))*2) # 2x for org and dest \n",
    "    else:\n",
    "        net = TrajectorySN(n_features=len(transformer.features_traj)) \n",
    "    net = nn.DataParallel(net)\n",
    "    net.to(device)\n",
    "    return train_g, val_g, net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 0\n",
      "torch.Size([9, 9, 4])\n",
      "torch.Size([9, 9, 4]) torch.Size([9, 9, 4])\n",
      "[1, 1, 1, 1, 0, 1, 0, 1, 0]\n",
      "[3, 4, 2, 9, 4, 6, 5, 2, 5]\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# slow\n",
    "params = {\n",
    "    'batch_size': 16,\n",
    "    'shuffle': True,\n",
    "    'collate_fn': zero_padding\n",
    "}\n",
    "train_g, val_g, net = get_data_and_model(params, mode=mode)\n",
    "count = 0\n",
    "for i, (x1, x2, y, x_seq_lens, max_seq_len) in enumerate(train_g):\n",
    "    print(f'Batch: {i}')\n",
    "    print(x1.shape)\n",
    "    print(x2[0].shape, x2[0].shape)\n",
    "    print(y)\n",
    "    print(x_seq_lens)\n",
    "    print(max_seq_len)\n",
    "    if count >=2:\n",
    "        break\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_prf(y, y_p):\n",
    "    p = round(precision_score(y, y_p, average='weighted'), 2)\n",
    "    r = round(recall_score(y, y_p, average='weighted'), 2)\n",
    "    f = round(f1_score(y, y_p, average='weighted'), 2)\n",
    "    return p,r,f\n",
    "\n",
    "def get_metric(metric, i, loss, acc, p, r, f, time):\n",
    "    metric['iter'].append(i)\n",
    "    metric['loss'].append(loss)\n",
    "    metric['acc'].append(acc)\n",
    "    metric['p'].append(p); metric['r'].append(r); metric['f'].append(f)\n",
    "    metric['time_mins'].append(time)\n",
    "    return metric\n",
    "\n",
    "def write_metric(tm, vm, mtype, epoch, batch):\n",
    "    file_tm = f'train_{mtype}_{epoch}_{batch}.json'\n",
    "    runs_dir = os.path.join(file_dir, '../runs', run_name)\n",
    "    if not os.path.exists(runs_dir):\n",
    "        os.mkdir(runs_dir)\n",
    "    with open (os.path.join(runs_dir, file_tm), 'w') as f:\n",
    "        json.dump(tm, f)\n",
    "    file_vm = f'val_{mtype}_{epoch}_{batch}.json'\n",
    "    with open (os.path.join(runs_dir, file_vm), 'w') as f:\n",
    "        json.dump(vm, f)\n",
    "\n",
    "def train(model, train_g, val_g, optimizer, criterion, threshold, epoch, print_at, mtype='DN'):\n",
    "    model.train()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    epoch_running_loss = 0.0\n",
    "    tic = time.time()\n",
    "    iterations = 0\n",
    "    train_metric = {\n",
    "        'iter': [],\n",
    "        'loss': [],\n",
    "        'acc': [],\n",
    "        'p': [],\n",
    "        'r': [],\n",
    "        'f': [],\n",
    "        'time_mins': []\n",
    "    }\n",
    "    val_metric = {\n",
    "        'iter': [],\n",
    "        'loss': [],\n",
    "        'acc': [],\n",
    "        'p': [],\n",
    "        'r': [],\n",
    "        'f': [],\n",
    "        'time_mins': []\n",
    "    }\n",
    "    for i in range(epoch):\n",
    "        for x1, x2, y, x_seq_lens, max_seq_len in train_g:\n",
    "            x1, y, x_seq_lens = torch.Tensor(x1).to(device), torch.Tensor(y).to(device), torch.Tensor(x_seq_lens).to(device)\n",
    "            org = x2[0]\n",
    "            dst = x2[1]\n",
    "            org = torch.Tensor(org).to(device)\n",
    "            dst = torch.Tensor(dst).to(device)\n",
    "            x2 = [org, dst]\n",
    "            # y = torch.Tensor(y)\n",
    "            # Zero your gradients for every batch!\n",
    "            optimizer.zero_grad()\n",
    "            #FORWARD PASS\n",
    "            if mtype == 'DN':\n",
    "                output = model(x1, x2, x_seq_lens)\n",
    "                output = torch.squeeze(output)\n",
    "                if len(output.shape) == 0:\n",
    "                    output = output.unsqueeze(0)\n",
    "                loss = criterion(output, y) \n",
    "                predicted_vals = (output > threshold)*1\n",
    "            else:\n",
    "                out1, out2 = model(x1, x2, x_seq_lens)\n",
    "                loss = criterion(out1, out2, y)\n",
    "                predicted_vals = (torch.pairwise_distance(out1, out2) > threshold)*1\n",
    "            # Compute the loss and its gradients\n",
    "            loss.backward()\n",
    "            # Adjust learning weights\n",
    "            optimizer.step()\n",
    "            epoch_running_loss += loss.item()\n",
    "            # Store Predictions\n",
    "            y_pred.extend(predicted_vals.tolist())\n",
    "            y_true.extend(y.tolist())\n",
    "            iterations += 1\n",
    "        MODEL_SAVE_PATH = os.path.join(file_dir, '../runs', run_name, f'Epoch{i}.pth')\n",
    "        if not os.path.exists(os.path.join(file_dir, '../runs', run_name)):\n",
    "            os.mkdir(os.path.join(file_dir, '../runs', run_name))\n",
    "        torch.save({\n",
    "            'epoch': i,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "            }, MODEL_SAVE_PATH)\n",
    "        if i % print_at == print_at-1:\n",
    "            train_time = round((time.time()-tic)/60.0, 2)\n",
    "            print(f'Epoch Time (min): {train_time}')\n",
    "            train_loss = round(epoch_running_loss / iterations, 4) # avg loss\n",
    "            train_acc = round(accuracy_score(y_true, y_pred), 2)\n",
    "            tp, tr, tf = get_prf(y_true, y_pred)\n",
    "            train_metric = get_metric(train_metric, i+1, train_loss, train_acc, tp, tr, tf, train_time)\n",
    "            tic = time.time()\n",
    "            val_loss, val_acc, vp, vr, vf = test(model, val_g, criterion, threshold, mtype)\n",
    "            val_time = round((time.time()-tic)/60.0, 2)\n",
    "            val_metric = get_metric(val_metric, i+1, val_loss, val_acc, vp, vr, vf, val_time)\n",
    "            print(f'Prediction Time (min): {val_time}')\n",
    "            print(\n",
    "                f'Epoch {i + 1}, Loss (Train, Val) : {train_loss}, {val_loss}, Accuracy (Train, Val): {train_acc}, {val_acc}, PRF (Val): {vp},{vr},{vf}'\n",
    "            )\n",
    "            print(\"***********************************************************\")\n",
    "            write_metric(train_metric, val_metric, mtype, epoch, train_g.batch_size)\n",
    "            tic = time.time()\n",
    "            model.train()\n",
    "    return train_metric, val_metric\n",
    "                          \n",
    "def test(model, test_loader, criterion, threshold, mtype='DN'):\n",
    "    #model in eval mode skips Dropout etc\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    running_loss = 0.0\n",
    "    # set the requires_grad flag to false as we are in the test mode\n",
    "    with torch.no_grad():\n",
    "        for x1, x2, y, x_seq_lens, max_seq_len in test_loader:\n",
    "            x1, y, x_seq_lens = torch.Tensor(x1).to(device), torch.Tensor(y).to(device), torch.Tensor(x_seq_lens).to(device)\n",
    "            org = x2[0]\n",
    "            dst = x2[1]\n",
    "            org = torch.Tensor(org).to(device)\n",
    "            dst = torch.Tensor(dst).to(device)\n",
    "            x2 = [org, dst]\n",
    "            # y = torch.Tensor(y)\n",
    "            # the model on the data\n",
    "            if mtype == 'DN':\n",
    "                output = model(x1, x2, x_seq_lens)\n",
    "                output = torch.squeeze(output)\n",
    "                if len(output.shape) == 0:\n",
    "                    output = output.unsqueeze(0)\n",
    "                loss = criterion(output, y) \n",
    "                pred = np.array((output.cpu() > threshold)*1)\n",
    "            else:\n",
    "                out1, out2 = model(x1, x2, x_seq_lens)\n",
    "                loss = criterion(out1, out2, y)\n",
    "                pred = np.array((torch.pairwise_distance(out1, out2) > threshold)*1)\n",
    "            target = y.float()\n",
    "            running_loss += loss.item()\n",
    "            y_true.extend(target.tolist()) \n",
    "            y_pred.extend(pred.reshape(-1).tolist())\n",
    "    avg_loss = round(running_loss / len(test_loader), 4)\n",
    "    acc = round(accuracy_score(y_true, y_pred), 2)\n",
    "    p,r,f = get_prf(y_true, y_pred)\n",
    "    return avg_loss, acc, p,r,f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def train_DN(train_g, val_g, net, lr, threshold, num_epochs, print_at):\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    train_metric, val_metric = train(\n",
    "        net, train_g, val_g, optimizer, criterion, threshold, num_epochs, print_at, mtype='DN'\n",
    "    )\n",
    "    return train_metric, val_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def train_SN(train_g, val_g, net, lr, threshold, num_epochs, print_at):\n",
    "    criterion = ContrastiveLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    train_metric, val_metric = train(\n",
    "        net, train_g, val_g, optimizer, criterion, threshold, num_epochs, print_at, mtype='SN'\n",
    "    )\n",
    "    return train_metric, val_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not find pre-trained weights at /Users/arunabha/fourkites/codebase/a3/paper/DifferenceNet/ti/ti/../runs/run_simulatedsubtraj_Batch4_EPOCHS10/Epoch998.pth, starting training without them\n",
      "Epoch Time (min): 0.0\n",
      "Prediction Time (min): 0.0\n",
      "Epoch 1, Loss (Train, Val) : 0.6667, 0.7961, Accuracy (Train, Val): 0.56, 0.0, PRF (Val): 0.0,0.0,0.0\n",
      "***********************************************************\n",
      "Epoch Time (min): 0.0\n",
      "Prediction Time (min): 0.0\n",
      "Epoch 2, Loss (Train, Val) : 0.7069, 0.6046, Accuracy (Train, Val): 0.44, 1.0, PRF (Val): 1.0,1.0,1.0\n",
      "***********************************************************\n",
      "Epoch Time (min): 0.0\n",
      "Prediction Time (min): 0.0\n",
      "Epoch 3, Loss (Train, Val) : 0.6937, 0.6061, Accuracy (Train, Val): 0.48, 1.0, PRF (Val): 1.0,1.0,1.0\n",
      "***********************************************************\n",
      "Epoch Time (min): 0.0\n",
      "Prediction Time (min): 0.0\n",
      "Epoch 4, Loss (Train, Val) : 0.7062, 0.6083, Accuracy (Train, Val): 0.44, 1.0, PRF (Val): 1.0,1.0,1.0\n",
      "***********************************************************\n",
      "Epoch Time (min): 0.0\n",
      "Prediction Time (min): 0.0\n",
      "Epoch 5, Loss (Train, Val) : 0.7017, 0.6159, Accuracy (Train, Val): 0.44, 1.0, PRF (Val): 1.0,1.0,1.0\n",
      "***********************************************************\n",
      "Epoch Time (min): 0.0\n",
      "Prediction Time (min): 0.0\n",
      "Epoch 6, Loss (Train, Val) : 0.7098, 0.6213, Accuracy (Train, Val): 0.41, 1.0, PRF (Val): 1.0,1.0,1.0\n",
      "***********************************************************\n",
      "Epoch Time (min): 0.0\n",
      "Prediction Time (min): 0.0\n",
      "Epoch 7, Loss (Train, Val) : 0.7063, 0.6246, Accuracy (Train, Val): 0.41, 1.0, PRF (Val): 1.0,1.0,1.0\n",
      "***********************************************************\n",
      "Epoch Time (min): 0.0\n",
      "Prediction Time (min): 0.0\n",
      "Epoch 8, Loss (Train, Val) : 0.7022, 0.766, Accuracy (Train, Val): 0.43, 0.0, PRF (Val): 0.0,0.0,0.0\n",
      "***********************************************************\n",
      "Epoch Time (min): 0.0\n",
      "Prediction Time (min): 0.0\n",
      "Epoch 9, Loss (Train, Val) : 0.7028, 0.6267, Accuracy (Train, Val): 0.44, 1.0, PRF (Val): 1.0,1.0,1.0\n",
      "***********************************************************\n",
      "Epoch Time (min): 0.0\n",
      "Prediction Time (min): 0.0\n",
      "Epoch 10, Loss (Train, Val) : 0.7043, 0.762, Accuracy (Train, Val): 0.44, 0.0, PRF (Val): 0.0,0.0,0.0\n",
      "***********************************************************\n"
     ]
    }
   ],
   "source": [
    "# slow\n",
    "# usage: train_DN\n",
    "params = {\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'shuffle': True,\n",
    "    'collate_fn': zero_padding\n",
    "}\n",
    "lr = 1e-3\n",
    "threshold = 0.5\n",
    "num_epochs = EPOCHS\n",
    "print_at = 1\n",
    "train_g, val_g, net = get_data_and_model(params, model='DN', mode=mode)\n",
    "MODEL_SAVE_PATH = os.path.join(file_dir, '../runs', run_name, f'Epoch{998}.pth')\n",
    "if os.path.exists(MODEL_SAVE_PATH):\n",
    "    print('Loading pre-trained model and optimizer weights from ', MODEL_SAVE_PATH)\n",
    "    checkpoint = torch.load(MODEL_SAVE_PATH)\n",
    "    net.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    net.train()\n",
    "else:\n",
    "    print('Did not find pre-trained weights at %s, starting training without them'%(MODEL_SAVE_PATH))\n",
    "_, _ = train_DN(train_g, val_g, net, lr, threshold, num_epochs, print_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "if __name__ == '__main__' and '__file__' in globals():\n",
    "    args = sys.argv[1:]\n",
    "    parser = argparse.ArgumentParser()\n",
    "    models = ['SN', 'DN']\n",
    "    parser.add_argument(\n",
    "        '-m', '--model',\n",
    "        help=\"\"\"Choose model, SN : Siamese Net, DN : Difference Net\"\"\",\n",
    "        choices=models\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '-e', '--epoch',\n",
    "        help=\"\"\"Number of Epochs\"\"\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '-p', '--print',\n",
    "        help=\"\"\"Print at every p step, p must not be greater than e\"\"\"\n",
    "    )\n",
    "    results = parser.parse_args(args)\n",
    "    params = {\n",
    "        'batch_size': 4,\n",
    "        'shuffle': True,\n",
    "        'collate_fn': zero_padding\n",
    "    }\n",
    "    lr = 1e-3\n",
    "    threshold = 0.5\n",
    "    num_epochs = int(results.epoch) if results.epoch else 10\n",
    "    print_at = int(results.print) if results.print else 1\n",
    "    if print_at > num_epochs:\n",
    "        raise ValueError('p must not be greater than e')\n",
    "    mtype = results.model if results.model else 'DN'\n",
    "    print(f'Training starting with: model={mtype}, epoch={num_epochs}, print every={print_at}')\n",
    "    train_g, val_g, net = get_data_and_model(params, mtype)\n",
    "    if mtype == 'DN':\n",
    "        train_DN(train_g, val_g, net, lr, threshold, num_epochs, print_at)\n",
    "    else:\n",
    "        train_SN(train_g, val_g, net, lr, threshold, num_epochs, print_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_prep.ipynb.\n",
      "Converted 01_dataloader.ipynb.\n",
      "Converted 02_model.ipynb.\n",
      "Converted 03_train.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
