{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "> Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from nbdev.showdoc import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Difference(nn.Module):\n",
    "    '''Difference Layer'''\n",
    "    def __init__(self, mode = 'simple'):\n",
    "        super(Difference, self).__init__()\n",
    "        self.mode = mode\n",
    "      \n",
    "    def forward(self, x1, x2):\n",
    "        '''Difference Layer: supports 3 types (simple, abs, square)'''\n",
    "        if self.mode == 'simple':\n",
    "            return x1 - x2\n",
    "        elif self.mode == 'abs':\n",
    "            return torch.abs(x1 - x2)\n",
    "        elif self.mode == 'square':\n",
    "            return torch.square(x1 - x2)\n",
    "        else:\n",
    "            raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class TrajectoryDN(nn.Module):\n",
    "    '''Trajectory Identification using Difference Net'''\n",
    "    def __init__(self, diff_net, n_features):\n",
    "        super(TrajectoryDN, self).__init__()\n",
    "        self.diff_net = diff_net\n",
    "        self.n_features = n_features\n",
    "        self.n_hidden_rnn = 64 # number of hidden states for RNN\n",
    "        self.n_layers_rnn = 2 # number of RNN layers (stacked)\n",
    "        self.lstm = torch.nn.LSTM(\n",
    "            input_size = self.n_features, \n",
    "            hidden_size = self.n_hidden_rnn,\n",
    "            num_layers = self.n_layers_rnn, \n",
    "            batch_first = True\n",
    "        )\n",
    "        self.fcn = nn.Sequential(\n",
    "            nn.Linear(self.n_hidden_rnn, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x1, x2, x_seq_lens): \n",
    "        # DifferenceNet\n",
    "        x_diff_org = self.diff_net(x1, x2[0]) # (B X T X F)\n",
    "        \n",
    "        x_diff_dest = self.diff_net(x1, x2[1]) # (B X T X F)\n",
    "        x = torch.cat((x_diff_org, x_diff_dest), dim=2) # (B X T X F*2)\n",
    "        # Pack padded batch of sequences for RNN module\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(x, x_seq_lens.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        # Forward pass through LSTM\n",
    "        outputs, (hidden, cell) = self.lstm(packed)\n",
    "        # FCN\n",
    "        x = hidden[-1] # Use the hidden state from the last LSTM in a stacked LSTM\n",
    "        x = self.fcn(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"TrajectoryDN\" class=\"doc_header\"><code>class</code> <code>TrajectoryDN</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h2>\n",
       "\n",
       "> <code>TrajectoryDN</code>(**`diff_net`**, **`n_features`**) :: `Module`\n",
       "\n",
       "Trajectory Identification using Difference Net"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TrajectoryDN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ![TDN](../images/TrajectoryDN.jpeg) -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slow\n",
    "# usage: TrajectoryDN\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from ti.dataloader import DatasetTraj, zero_padding, getSTW, splitData\n",
    "from ti.prep import Transformer\n",
    "\n",
    "# data generator\n",
    "params = {\n",
    "    'batch_size': 16,\n",
    "    'shuffle': True,\n",
    "    'collate_fn': zero_padding\n",
    "}\n",
    "\n",
    "stw = getSTW()\n",
    "tr_range, val_range, ts_range = splitData(len(stw))\n",
    "\n",
    "train_g = DataLoader(DatasetTraj(tr_range, stw, mode='sim'), **params)\n",
    "transformer = Transformer()\n",
    "\n",
    "diff_net = Difference(mode='simple')\n",
    "net = TrajectoryDN(diff_net, n_features=len(transformer.features_traj)*2) # 2x for org and dest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch\n",
      "torch.Size([9, 15, 4])\n",
      "torch.Size([9, 15, 4]) torch.Size([9, 15, 4])\n",
      "tensor([0., 0., 1., 0., 1., 0., 1., 0., 0.])\n",
      "tensor([ 4.,  3.,  7., 15.,  7.,  9.,  6.,  7.,  3.])\n",
      "15\n",
      "tensor([[0.5010],\n",
      "        [0.5012],\n",
      "        [0.5007],\n",
      "        [0.5007],\n",
      "        [0.5007],\n",
      "        [0.5006],\n",
      "        [0.5008],\n",
      "        [0.5007],\n",
      "        [0.5012]], grad_fn=<SigmoidBackward>)\n"
     ]
    }
   ],
   "source": [
    "# slow\n",
    "# usage: TrajectoryDN\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "count = 0\n",
    "net.to(device)\n",
    "for x1, x2, y, x_seq_lens, max_seq_len in train_g:\n",
    "    x1, y, x_seq_lens = torch.Tensor(x1).to(device), torch.Tensor(y).to(device), torch.Tensor(x_seq_lens).to(device)\n",
    "    org = x2[0]\n",
    "    dst = x2[1]\n",
    "    org = torch.Tensor(org).to(device)\n",
    "    dst = torch.Tensor(dst).to(device)\n",
    "    x2 = [org, dst]\n",
    "    print('Batch')\n",
    "    print(x1.shape)\n",
    "    print(x2[0].shape, x2[0].shape)\n",
    "    print(y)\n",
    "    print(x_seq_lens)\n",
    "    print(max_seq_len)\n",
    "    print(net(x1, x2, x_seq_lens))\n",
    "    if count >= 0:\n",
    "        break\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class TrajectorySN(nn.Module):\n",
    "    '''Trajectory Identification using Siamese Net'''\n",
    "    def __init__(self, n_features, embed_size=16):\n",
    "        super(TrajectorySN, self).__init__()\n",
    "        self.n_features = n_features\n",
    "        self.embed_size = embed_size\n",
    "        self.n_hidden_rnn = 64 # number of hidden states for RNN\n",
    "        self.n_layers_rnn = 2 # number of RNN layers (stacked)\n",
    "        self.lstm = torch.nn.LSTM(\n",
    "            input_size = self.n_features, \n",
    "            hidden_size = self.n_hidden_rnn,\n",
    "            num_layers = self.n_layers_rnn, \n",
    "            batch_first = True\n",
    "        )\n",
    "        self.traj_embed = nn.Sequential(\n",
    "            nn.Linear(self.n_hidden_rnn, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, self.embed_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.stop_embed = nn.Sequential(\n",
    "            nn.Linear(self.n_features*2, 32), # 2x for org and dest \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, self.embed_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x1, x2, x_seq_lens): \n",
    "        # Siam 1: x1\n",
    "        # Pack padded batch of sequences for RNN module\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(\n",
    "            x1, \n",
    "            x_seq_lens, \n",
    "            batch_first=True, \n",
    "            enforce_sorted=False\n",
    "        )\n",
    "        # Forward pass through LSTM\n",
    "        outputs, (hidden, cell) = self.lstm(packed)\n",
    "        # FCN\n",
    "        x1 = hidden[-1] # Use the hidden state from the last LSTM in a stacked LSTM\n",
    "        x1 = self.traj_embed(x1)\n",
    "        # Siamese Prep: x2\n",
    "        x20 = x2[0][:,-1,:]\n",
    "        x21 = x2[1][:,-1,:]\n",
    "        x2 = torch.cat((x20, x21), dim=1)\n",
    "        # Siam 2: x2\n",
    "        x2 = self.stop_embed(x2)\n",
    "        return x1, x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"TrajectorySN\" class=\"doc_header\"><code>class</code> <code>TrajectorySN</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h2>\n",
       "\n",
       "> <code>TrajectorySN</code>(**`n_features`**, **`embed_size`**=*`16`*) :: `Module`\n",
       "\n",
       "Trajectory Identification using Siamese Net"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TrajectorySN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ContrastiveLoss(nn.Module):\n",
    "    '''Contrastive Loss'''\n",
    "    def __init__(self, margin=1.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        # Find the pairwise distance or eucledian distance of two output feature vectors\n",
    "        euclidean_distance = torch.pairwise_distance(output1, output2)\n",
    "        # perform contrastive loss calculation with the distance\n",
    "        pos_ = (1-label) * torch.pow(euclidean_distance, 2)\n",
    "        neg_ = label * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2)\n",
    "        loss_contrastive = torch.mean(pos_ + neg_)\n",
    "        return loss_contrastive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ![TSN](../images/TrajectorySN.jpeg) -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def contastive_loss(x1, x2, y, margin=1.0):\n",
    "    distance = torch.pairwise_distance(x1, x2)\n",
    "    pos_part = (1.0 - y) * torch.pow(distance, 2)\n",
    "    neg_part = y * torch.relu(torch.pow(margin - distance, 2))\n",
    "    loss = 0.5 * (pos_part + neg_part)\n",
    "    return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slow\n",
    "# usage: TrajectorySN\n",
    "net = TrajectorySN(n_features=len(transformer.features_traj)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch\n",
      "torch.Size([9, 23, 4])\n",
      "torch.Size([9, 23, 4]) torch.Size([9, 23, 4])\n",
      "tensor([1., 1., 1., 0., 0., 1., 1., 1., 1.])\n",
      "[8, 3, 3, 5, 21, 23, 4, 4, 7]\n",
      "23\n",
      "torch.Size([9, 16]) torch.Size([9, 16])\n",
      "0.1713111698627472\n"
     ]
    }
   ],
   "source": [
    "# slow\n",
    "# usage: TrajectorySN\n",
    "count = 0\n",
    "for x1, x2, y, x_seq_lens, max_seq_len in train_g:\n",
    "    print('Batch')\n",
    "    print(x1.shape)\n",
    "    print(x2[0].shape, x2[0].shape)\n",
    "    y = torch.Tensor(y)\n",
    "    print(y)\n",
    "    print(x_seq_lens)\n",
    "    print(max_seq_len)\n",
    "    x1, x2 = net(x1, x2, x_seq_lens)\n",
    "    print(x1.shape, x2.shape)\n",
    "    print(contastive_loss(x1, x2, y).item())\n",
    "    if count >= 0:\n",
    "        break\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_prep.ipynb.\n",
      "Converted 01_dataloader.ipynb.\n",
      "Converted 02_model.ipynb.\n",
      "Converted 03_train.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
